{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предлагается реализовать классификатор логистическая регрессия и обучить его на датасете Large Movie Review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала импортируем все необходимые для работы пакеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import math\n",
    "from __future__ import division\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт датасета, его предобработка и токенизация, построение словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные. Как и в **Assignment 1**, у нас есть три выборки: обучающая (train), размеченная тестовая (dev) и неразмеченная тестовая (test). На размеченной тестовой выборке мы тестируем классификатор и определяем его точность. Результаты работы классификатора на неразмеченной тестовой выборке проверяются на сервере СompAI, метки для нее не предоставляются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../FILIMDB'\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    Reads specified file, returns list of strings\n",
    "    :param file_name: file name in data_dir folder\n",
    "    :returns list of strings\n",
    "    \"\"\"\n",
    "    print('Loading %s' % file_name)\n",
    "    data_path = os.path.join(data_dir, file_name)\n",
    "    with open(data_path) as input_data:\n",
    "        lines = input_data.readlines()\n",
    "        lines = [l.strip() for l in lines]\n",
    "    \n",
    "    print('Loaded %d lines' % len(lines))\n",
    "    return lines\n",
    "\n",
    "train_texts, train_labels = load_data('train.texts'), load_data('train.labels')\n",
    "dev_texts, dev_labels = load_data('dev.texts'), load_data('dev.labels')\n",
    "test_texts = load_data('test.texts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем разметку из 'pos','neg' в 1 и 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_labels(labels_str):\n",
    "    labels_int = np.array([int(label == 'pos') for label in labels_str])\n",
    "    return np.reshape(labels_int, (len(labels_int),1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels =transform_labels(train_labels)\n",
    "dev_labels = transform_labels(dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним основную предобработку датасета:\n",
    "- Отделить пунктуацию от слов пробелами\n",
    "- Вычистить все лишнее: специальные символы, остатки html-разметки и т.д. При этом обычно не надо вычищать буквы с акцентами (à, á...). 'Мусорные' символы лучше не удалять, а заменять на пробелы, иначе слова могут склеиться.\n",
    "- Перевести буквы в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(s, lower=True):\n",
    "    s = re.sub(r'([^ \\w])', r' \\1 ',s)\n",
    "    s = re.sub(r' +', r' ',s)\n",
    "    if lower:\n",
    "        s = s.lower()\n",
    "    return s.strip().split(' ')\n",
    "\n",
    "tokenized_train_texts = [tokenize(r) for r in train_texts]\n",
    "tokenized_dev_texts = [tokenize(r) for r in dev_texts]\n",
    "tokenized_test_texts = [tokenize(r) for r in test_texts]\n",
    "\n",
    "# sanity check\n",
    "assert all(len(x) > 0 for x in tokenized_train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на результат процедуры токенизации на случайном отзыве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,len(tokenized_train_texts)) #choosing random index\n",
    "print(\"Это исходный отзыв: {}\".format(train_texts[idx]))\n",
    "print(\"Это отзыв после предобработки и токенизации: {}\".format(tokenized_train_texts[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим словарь уникальных слов, которые встречаются в обучающей выборке. Удалите слова, которые встречаются в словаре менее 5 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшей удобный работы преобразуем наш словарь в Python тип данных dict, где ключи - это наш словарь уникальные слова, а порядковый номер этого слова в сортированном по алфавиту словаре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_vocabulary(unique_words):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = transform_vocabulary(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Векторизация отзывов, построение матрицы обучающей и тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы обучить логистическую регрессию на нашем датасете, нам необходимо преобразовать его в матричный вид, где обучающая и тестовая выборка будут представлены в виде матриц размера $N \\times V$, где $N$ - количество отзывов в выборке, $V$ - количество слов в словаре, а $j$-й элемент $i$-й строки соответствует частоте появления в $i$-м отзыве $j$-го токена из словаря. Для оптимизации работы с памятью мы будем строить  матрицы типа __[scipy.sparse.csr_matrix ](http://www.scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CountVectorizer(texts, vocabulary):\n",
    "        \"\"\"\n",
    "            Transform a collection of texts to a matrix of token counts\n",
    "            In order to be memory-efficient, the matrix of token counts \n",
    "            has a sparse representation of the counts using scipy.sparse.csr_matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        j_indices = [] #indices is array of column indices\n",
    "        indptr = [] # indptr points to row starts in indices and data\n",
    "        values = [] #values is array of corresponding nonzero values\n",
    "        indptr.append(0)\n",
    "        for text in texts:\n",
    "            token_counter = {}\n",
    "            for token in text:\n",
    "                try:\n",
    "                      # YOUR CODE HERE\n",
    "                    raise NotImplementedError()\n",
    "                except KeyError:\n",
    "                    # ignore out-of-vocabulary tokens\n",
    "                    continue\n",
    "                    \n",
    "            j_indices.extend(token_counter.keys())\n",
    "            \n",
    "            values.extend(token_counter.values())\n",
    "            indptr.append(len(j_indices))\n",
    "        \n",
    "        X = scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                          shape=(len(indptr) - 1, len(vocabulary)),\n",
    "                          )\n",
    "    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы проверить и отладить работу функции CountVectorizer() попбробуйте построить матрицу для игрушечного датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_texts = ['abs xux abs dud', 'lul omo xux xux xux']\n",
    "tokenized_toy_texts = [tokenize(r) for r in toy_texts]\n",
    "unique_words_toy = set(w for text in tokenized_toy_texts for w in text)\n",
    "vocabulary_toy = transform_vocabulary(unique_words_toy)\n",
    "print(\"Словарь игрушечного датасета: {}\".format(sorted(unique_words_toy)))\n",
    "\n",
    "\n",
    "X_toy = CountVectorizer(tokenized_toy_texts, vocabulary_toy)\n",
    "print(\"Матрица векторизованных отзывов игрушечного датасета имеет размер {} и равна \\n{}\".format(X_toy.shape, X_toy.todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедитесь, что вы получили матрицу размера $2\\times5$ равную: <br>\n",
    "$$[[2\\: 1\\: 0\\: 0\\: 1] \\\\\n",
    "[0\\: 0\\: 1\\: 1\\: 3]]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы проверили, что функция CountVectorizer() работает корректно, построим матричные представления для нашей обучающей и тестовых выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = CountVectorizer(tokenized_train_texts, vocabulary)\n",
    "X_dev = CountVectorizer(tokenized_dev_texts, vocabulary)\n",
    "X_test = CountVectorizer(tokenized_test_texts, vocabulary)\n",
    "\n",
    "print(\"Размерность матрицы для обучающей выборки равна {}\".format(X_train.shape))\n",
    "print(\"Размерность матрицы для открытой тестовой выборки равна {}\".format(X_dev.shape))\n",
    "print(\"Размерность матрицы для закрытой тестовой выборки равна {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удостоверьтесь, что размер получившихся матриц равен $(25000 \\times 29204), (25000 \\times 29204), (10599 \\times 29204)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы и говорили в задании, для удобства мы будем использовать $w^Tx_{\\{i\\}}$ запись, однако для этого нам нужно присоединить к входным векторам $x_{\\{i\\}}$ единицу, т.е. $x_{\\{i\\}} := [1; x_{\\{i\\}}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_one(X):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = concat_one(X_train)\n",
    "X_dev = concat_one(X_dev)\n",
    "X_test = concat_one(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что сейчас наша обучающая выборки упорядочены, для качественного обучения нам необходимо перемешать обучающую выборку случайным образом. Напишем соответствующую функцию shuffle(X,y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, train_labels = shuffle(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Построение логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии нам понадобится сигмоида:\n",
    "\n",
    "$$ sigmoid(z) = {\\frac {1}{1+e^{-z}}}$$\n",
    "\n",
    "Напишите её:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем вектор параметров W. Инициализировать его можно нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(dim):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишем основную фунцию, которая будет:\n",
    "\n",
    "    1) Вычислять результат для классификатора по формуле:\n",
    "    \n",
    "$$h(x) = sigmoid(x^T w)$$\n",
    "\n",
    "    2) Вычислять функцию потерь по формуле:\n",
    "    \n",
    "$$ L = - \\frac1{N} \\sum_{i=1}^N(y_i \\log h(x_i) + (1 - y_i) \\log (1 - h(x_i)) + \\alpha\\sum_{j=1}^M(w_j)^2$$\n",
    "\n",
    "    3) Вычислять точность, с которой работает классификатор\n",
    "    \n",
    "    4) Находить производные:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w_j} = \\frac{1}{N}x \\:(h(x)-y)^T + 2\\lambda w_j$$\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w_0} = \\frac{1}{N} \\sum_{i=1}^N (h(x_{i})-y_{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(X, y, w, alpha):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    " \n",
    "    assert (dw.shape == w.shape)\n",
    "    return dw, cost, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_inputs = X_toy\n",
    "toy_targets = np.zeros((2, 1))\n",
    "toy_dim = 5\n",
    "print(\"Inputs: \", toy_inputs.todense())\n",
    "print(\"Targets: \", toy_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_grads, toy_cost, toy_acc = propagate(toy_inputs, toy_targets,(initialize_parameters(dim = toy_dim)), alpha = 1e-4)\n",
    "\n",
    "print (\"dw = \" + str(toy_grads))\n",
    "print (\"toy_cost = \" + str(toy_cost))\n",
    "print (\"toy_acc = \" + str(toy_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удостоверьтесь, что на выходе получились следующие значения:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "        <td> [[ 0.5]\n",
    " [ 0.25]\n",
    " [0.25]\n",
    " [0.25]\n",
    " [1.]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** toy_cost **  </td>\n",
    "        <td> 0.69314718056 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** toy_acc **  </td>\n",
    "        <td> 1 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также напишем функцию обновления весов, используя следующие формулы:\n",
    "\n",
    "$$w = w - \\lambda * dL/dW$$\n",
    "\n",
    "При этом $\\lambda$ - скорость обучения (learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(w,dw,learning_rate):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_toy_parameters = update_parameters(initialize_parameters(dim = toy_dim),toy_grads,0.01)\n",
    "w = new_toy_parameters\n",
    "print (\"w = \" + str(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удостоверьтесь, что на выходе получились следующие значения:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ -0.005 ]\n",
    " [ -0.0025]\n",
    " [ -0.0025]\n",
    " [ -0.0025]\n",
    " [ -0.01]]</td>\n",
    "    </tr>\n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также напишем функцию предсказания меток $\\hat{y}$ для заданных параметров w и выборки X размера $N \\times V$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(w, X):    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_toy = predict(w, toy_inputs)\n",
    "print(y_predict_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удостоверьтесь, что на выходе получились следующие значения: <br> [[ 0.] <br>\n",
    " [ 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда вся предварительная работа выполнена, можно начать обучение логистической регрессии. Установим значения гиперпараметров: скорость обучения, коэффициент регуляризации $\\alpha$, количество итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N, dims = X_train.shape\n",
    "\n",
    "learning_rate = 1e-3\n",
    "alpha = 1e-5\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 100\n",
    "num_batches = np.ceil(N / batch_size).astype('int')\n",
    "\n",
    "w = initialize_parameters(dim=dims)\n",
    "acc = 0\n",
    "best_acc = 0\n",
    "best_parameters = None\n",
    "costs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем обучение. Обратите внимание, что для ускорения сходимости, мы будем использовать mini_batch подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in  range(num_batches):\n",
    "        # form batch\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        # propagate\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        # propagate through whole train dataset and calculate cost, acc\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        costs.append(cost)\n",
    "        print(\"Epoch {} out of {}, Cost: {}, Acc: {}\".format(epoch,num_epochs, cost, acc))\n",
    "\n",
    "        # calculate cost and acc on dev dataset\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        print(\"Test acc: {}\".format(dev_acc))\n",
    "        \n",
    "        #save\n",
    "        if dev_acc > best_acc:\n",
    "            best_acc = dev_acc\n",
    "            best_parameters = w\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training time: {}, Best acc: {}\".format(end - start, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте нарисуем кривую обучения: cost vs iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iterations (per hundreds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Оптимизация гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас в качестве коэффициента $L_2$ регуляризации $\\alpha$ мы выбрали некоторое произвольное значение. Для подбора оптимального значения $\\alpha$ мы будем проводить валидацию на валидационной выборке. Для этого случайным образом перемешаем текущую обучающую выборку и разделим ее в соотношении 80:20 на две – новая (меньшего размера) обучающая выборка и валидационная выборка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, train_labels = shuffle(X_train, train_labels)\n",
    "small_train_size = int(math.ceil(X_train.shape[0]*0.8))\n",
    "X_small_train = X_train[:small_train_size]\n",
    "train_labels_small = train_labels[:small_train_size]\n",
    "X_valid =  X_train[small_train_size:]\n",
    "labels_valid = train_labels[small_train_size:]\n",
    "print(\"Размер новой обучающей выбоки равен {}, размер валидационной выборки равен {}\".format(X_small_train.shape[0], X_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем найти оптимальное значение $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, dims = X_small_train.shape\n",
    "\n",
    "learning_rate = 1e-3\n",
    "alphas = [1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 100\n",
    "num_batches = np.ceil(N / batch_size).astype('int')\n",
    "\n",
    "best_alpha = alphas[0]\n",
    "best_alpha_acc = 0\n",
    "best_alpha_parameters = None\n",
    "\n",
    "cost_train = np.zeros((len(alphas), num_epochs//10))\n",
    "\n",
    "for j, alpha in enumerate(alphas):\n",
    "    print(\"Коэффициент регуляризации = {}\".format(alpha))\n",
    "    w = initialize_parameters(dim=dims)\n",
    "    best_acc = 0\n",
    "    best_parameters = None\n",
    "      \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in  range(num_batches):\n",
    "            # form batch\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "            # propagate\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # propagate through whole train dataset and calculate cost, acc\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            print(\"Epoch {} out of {}, Cost: {}, Acc: {}\".format(epoch,num_epochs, cost, acc))\n",
    "\n",
    "            # calculate cost and acc on dev dataset\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "            #save\n",
    "            if valid_acc > best_acc:\n",
    "                best_acc = valid_acc\n",
    "                best_parameters = w\n",
    "            \n",
    "    if best_acc > best_alpha_acc:\n",
    "        best_alpha = alpha\n",
    "        best_alpha_acc = best_acc\n",
    "        best_alpha_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Оптимальное значение коэффициента регуляризации равно {} '.format(best_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь используя найденное значение $\\alpha$, обучим логистическую регрессию на всей обучающей выборке и оценим точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training time: {}, Best acc: {}\".format(end - start, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Загрузка результатов на сервер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя найденные оптимальные параметры, посчитаем метки для всех трех датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_best = best_parameters\n",
    "train_preds = predict(w_best, X_train)\n",
    "dev_preds = predict(w_best, X_dev)\n",
    "test_preds = predict(w_best, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим файл с прогнозами и отправим его на CompAI сервер. Для этого понадобится положить файл compai_ilimdb_sentiment.py, полученный при регистрации, в директорию с этим блокнотом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_file_name = \"preds.tsv\"\n",
    "with open(res_file_name, 'w') as outp:\n",
    "    for index, label in enumerate(train_preds):\n",
    "        print('train/%d\\t%s' % (index, label), file=outp)\n",
    "    for index, label in enumerate(dev_preds):\n",
    "        print('dev/%d\\t%s' % (index, label), file=outp)\n",
    "    for index, label in enumerate(test_preds):\n",
    "        print('test/%d\\t%s' % (index, label), file=outp)\n",
    "print('Predictions saved to %s' % res_file_name)\n",
    "\n",
    "%run compai_ilimdb_sentiment.py submit $res_file_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
